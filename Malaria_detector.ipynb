{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Malaria detector.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek-TyRnT/TyRnT/blob/master/Malaria_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yr4KYqbmLce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgKWXZX4lgDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link=\"https://drive.google.com/open?id=1FoZ5XNPxsKB75bq7zYZ8rpH5PJoRB988\"\n",
        "fluff, id = link.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('cell_images.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3eOq5NDmGDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(\"cell_images.zip\",'r') as zip:\n",
        "  zip.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XW25obWrCac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "data_dir=\"cell_images\"\n",
        "category_1=\"Parasitized\"\n",
        "category_2=\"Uninfected\"\n",
        "path_1=os.path.join(data_dir,category_1)\n",
        "path_2=os.path.join(data_dir,category_2)\n",
        "def image_generator(start,stop):\n",
        " i=start\n",
        " for j in range(start,stop):\n",
        "   image_1=cv2.imread(os.path.join(path_1,os.listdir(path_1)[j]),cv2.IMREAD_COLOR)\n",
        "   image_1=tf.image.resize(images=image_1,size=[224,224])\n",
        "   image_1=tf.reshape(image_1,shape=(1,224,224,3))\n",
        "   image_2=cv2.imread(os.path.join(path_2,os.listdir(path_2)[j]),cv2.IMREAD_COLOR)\n",
        "   image_2=tf.image.resize(images=image_2,size=[224,224])\n",
        "   image_2=tf.reshape(image_2,shape=(1,224,224,3))\n",
        "   if(start<=i and i<stop):\n",
        "    yield image_1/255,[True,False]\n",
        "    yield image_2/255,[False,True]\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkv2t6SLnTgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "dataset_train=tf.data.Dataset.from_generator(image_generator,args=[0,13780//2],output_types=(tf.float32,tf.int32),output_shapes=(tf.TensorShape([None,224,224,3]),tf.TensorShape([2])))\n",
        "dataset_val=tf.data.Dataset.from_generator(image_generator,args=[(13780//2)+1,13780],output_types=(tf.float32,tf.int32),output_shapes=(tf.TensorShape([None,224,224,3]),tf.TensorShape([2])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LPe4BbppHkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train=dataset_train.shuffle(buffer_size=100)\n",
        "dataset_val=dataset_val.shuffle(buffer_size=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP5dVjo6SbEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train=dataset_train.batch(batch_size=10)\n",
        "dataset_val=dataset_val.batch(batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-6M9M8a4_0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=0\n",
        "for img in dataset_train.take(150):\n",
        "  if i>137:\n",
        "   plt.imshow(img[0][0])\n",
        "   plt.show()\n",
        "  print(i)\n",
        "  i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx70Gfbg0wo6",
        "colab_type": "text"
      },
      "source": [
        "Alex net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzYf8yYlvGUr",
        "colab_type": "code",
        "outputId": "0728e3e3-239d-4962-b5f9-c56d0ddabf9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "inp=tf.keras.Input(shape=(224,224,3),dtype=tf.float32)\n",
        "network=tf.keras.layers.Conv2D(filters=96,kernel_size=(11,11),strides=4,padding='SAME',activation='relu')(inp)\n",
        "network=tf.nn.local_response_normalization(network,depth_radius=2,alpha=0.00002,beta=0.75)\n",
        "network=tf.keras.layers.Conv2D(filters=96,kernel_size=(3,3),strides=2,padding='VALID',activation=None)(network)\n",
        "network=tf.keras.layers.MaxPool2D(pool_size=(3,3),strides=2)(network)\n",
        "network=tf.keras.layers.Conv2D(filters=256,kernel_size=(5,5),strides=1,padding='SAME',activation='relu')(network)\n",
        "network=tf.nn.local_response_normalization(network,depth_radius=2,alpha=0.00002,beta=0.75)\n",
        "network=tf.keras.layers.MaxPool2D(pool_size=(3,3),strides=2)(network)\n",
        "network=tf.keras.layers.Conv2D(filters=384,kernel_size=(3,3),strides=1,padding='SAME',activation='relu')(network)\n",
        "network=tf.keras.layers.Conv2D(filters=384,kernel_size=(3,3),strides=1,padding='SAME',activation='relu')(network)\n",
        "network=tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=1,padding='SAME',activation='relu')(network)\n",
        "network=tf.keras.layers.Flatten()(network)\n",
        "network=tf.keras.layers.Dense(units=4096,activation='relu')(network)\n",
        "network=tf.keras.layers.Dropout(rate=0.5)(network)\n",
        "network=tf.keras.layers.Dense(units=1024,activation='relu')(network)\n",
        "network=tf.keras.layers.Dropout(rate=0.5)(network)\n",
        "output=tf.keras.layers.Dense(units=2,activation='softmax')(network)\n",
        "\n",
        "model=Model(inputs=inp,outputs=output)\n",
        "tf.keras.utils.plot_model(model)\n",
        "model.compile(optimizer=\"adam\",loss=tf.losses.BinaryCrossentropy(),metrics=[\"accuracy\"])\n",
        "model.fit_generator(dataset_train,epochs=10,validation_data=dataset_val,steps_per_epoch=1370,validation_steps=1370)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 1370 steps, validate for 1370 steps\n",
            "Epoch 1/10\n",
            "1370/1370 [==============================] - 301s 219ms/step - loss: 0.6946 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1370/1370 [==============================] - 297s 217ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1370/1370 [==============================] - 298s 217ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "1370/1370 [==============================] - 297s 217ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "1370/1370 [==============================] - 298s 217ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "1370/1370 [==============================] - 297s 217ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "1370/1370 [==============================] - 297s 217ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "1370/1370 [==============================] - 296s 216ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "1370/1370 [==============================] - 297s 217ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "1370/1370 [==============================] - 302s 220ms/step - loss: 3.7129 - accuracy: 0.5000 - val_loss: 7.6685 - val_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa4d0dfa0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr5ldur2JH0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "9cd536c9-7ab5-4472-e095-c94a55120b98"
      },
      "source": [
        "for img in dataset_val.take(10):\n",
        "  y=model.predict(img[0])\n",
        "  print(y,img[1])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]] tf.Tensor([0 1], shape=(2,), dtype=int32)\n",
            "[[1. 0.]] tf.Tensor([0 1], shape=(2,), dtype=int32)\n",
            "[[1. 0.]] tf.Tensor([0 1], shape=(2,), dtype=int32)\n",
            "[[1. 0.]] tf.Tensor([1 0], shape=(2,), dtype=int32)\n",
            "[[1. 0.]] tf.Tensor([0 1], shape=(2,), dtype=int32)\n",
            "[[1. 0.]] tf.Tensor([1 0], shape=(2,), dtype=int32)\n",
            "[[1. 0.]] tf.Tensor([1 0], shape=(2,), dtype=int32)\n",
            "[[1. 0.]] tf.Tensor([1 0], shape=(2,), dtype=int32)\n",
            "[[1. 0.]] tf.Tensor([1 0], shape=(2,), dtype=int32)\n",
            "[[1. 0.]] tf.Tensor([1 0], shape=(2,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bId2iKHHRR0Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98e8abd0-7aa0-40d1-f5b8-7f4cfda79e82"
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 34kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 34.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/5f/a1a02695b96d0e09c38abf7d1576b137979cea3d060d60891622cf61276d/google_auth-1.10.1-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-1.10.1 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}